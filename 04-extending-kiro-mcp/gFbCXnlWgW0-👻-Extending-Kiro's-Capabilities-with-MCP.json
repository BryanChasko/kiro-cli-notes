{"text": " Hey James, so there are a lot of MCP servers out there. But I heard about these two new ones that can really super charge Kuro and make you more productive. Can you tell me more about it? Yeah, absolutely. So with the AWS MCP servers, we have two new ones, as you said, we've got the API one. This makes it really easy to interact with AWS, query your resources, potentially make changes to your resources. And then we have the Knowledge One, which brings in documentation, things from the Builder Center. And so both of these together actually make you super productive when you're working with AWS. So let's dive in. I'll give you a quick demo. So here in Kuro, what I'm going to do is be able to edit this MCP.json file. We can do get to that by opening up the Kuro menu, going to MCP servers, hitting this edit button. And we'll see that I've put in both of those MCP servers, I just mentioned. The first one is that AWS API, MCP server. And that uses a tool called UV, a very used UV. No, I haven't. It's a great build tool for Python, makes it really easy to pull down a Python library and run it. So that's what we're using. We're pulling down that server and starting it up. I'm putting it to my AWS region, US East One. I'd give it a working directory because the AWS CLI actually needs to know what directory it's in if it's going to copy files, that sort of thing. And then I can also set this read-only read operations only to true if I want to just be safe to make sure that it's not going to go accidentally and mutating stuff in my AWS infrastructure. And so with this one, it does, it is going to give essentially the AI access to your AWS environment. So you probably want to put some safeguards and not use this for your production system, maybe just for exploring testing and that sort of thing. So that's the first one. Let me show you how to use it. I'm going to go into Kuro into the vibe mode. So what I'm going to do is tell it to you, list my S3 buckets. And it's going to think about that for a second because it's actually using a pretty sophisticated model to turn that into an AWS CLI command to then make the call up to AWS. So before it does anything, it's going to ask me, are you sure you want to do this? Here's what I'm going to do. Are you sure? And I'm going to say, yep, I'm sure run it. And then what will happen is we'll see the output from this call, kind of stream in there. But you'll see there, guys, it listed my S3 buckets, even gave me some information about when there created gives me a little summary. So great. Now I've got this like natural language interface to talk to my resources on AWS. Okay, the next one here is that knowledge server. So this one has access to a number of documents on AWS documentation, the new builder center. So index is all that and can search that. And so for that, I did have to use this MCP proxy, also using UV. And then I tell that the transport is the MCP streamable HTTP protocol. And then I just give it the URL. And now I can come in and ask it questions like, I'm going to say, how do I deploy with bedrock agent core runtime? And that's something that the model doesn't know, but this knowledge server knows. And so now it's going to say, like, hey, I'm going to search the documentation for information about that. I'm going to say, yep, I do want you to do that. So it's calling the MCP tool. And it's going to do a number of different operations. I can, I think, just say, like, accept all or whatever, but I'm going to prove each one individually. It's going to read documentation. So it's going to go through all these iterative steps, learning from the documentation. And then we'll give me a nice summary of something that is brand new, which is super cold to be able to have access to that type of information within Kuro. I think something with AWS before, it's always hard to find the correct documentation. So this makes it much easier. Yeah, exactly. Like, this gives you the natural language interface to the documentation, so you don't have to go search through the whole documentation website and the many other sites that are all indexed with this MCP tool as well. It's not just the normal documentation site. So you've probably had that situation where you open up like a hundred different tabs in your browser, and then you have to go read through all those. And this is essentially doing that all for you, doing that work for you, of taking all that information, distilling it down into exactly what you want to know. Great. We've got our documentation there for how to use this brand new agent core service. And those are our two MCP servers. So if you want to get started, the best way is to go to the GitHub page, let's get up.com slash AWS Labs slash MCP, and you can find that link below. And then go to the Getting Started with AWS, and you can find the information on those two MCP servers and how to install them into Kuro or wherever you want to use those. And I find really interesting is you could take these two MCP servers and use them together. So one can help you with documentation. One can actually help you craft and build your application using the API. If you liked this video, make sure you click like and subscribe, and let us know what you want us to build next.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.44, "text": " Hey James, so there are a lot of MCP servers out there.", "tokens": [50364, 1911, 5678, 11, 370, 456, 366, 257, 688, 295, 8797, 47, 15909, 484, 456, 13, 50536], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 1, "seek": 0, "start": 3.44, "end": 7.72, "text": " But I heard about these two new ones that can really super charge Kuro and make you more productive.", "tokens": [50536, 583, 286, 2198, 466, 613, 732, 777, 2306, 300, 393, 534, 1687, 4602, 591, 7052, 293, 652, 291, 544, 13304, 13, 50750], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 2, "seek": 0, "start": 7.72, "end": 9.16, "text": " Can you tell me more about it?", "tokens": [50750, 1664, 291, 980, 385, 544, 466, 309, 30, 50822], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 3, "seek": 0, "start": 9.16, "end": 10.56, "text": " Yeah, absolutely.", "tokens": [50822, 865, 11, 3122, 13, 50892], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 4, "seek": 0, "start": 10.56, "end": 16.240000000000002, "text": " So with the AWS MCP servers, we have two new ones, as you said, we've got the API one.", "tokens": [50892, 407, 365, 264, 17650, 8797, 47, 15909, 11, 321, 362, 732, 777, 2306, 11, 382, 291, 848, 11, 321, 600, 658, 264, 9362, 472, 13, 51176], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 5, "seek": 0, "start": 16.240000000000002, "end": 20.48, "text": " This makes it really easy to interact with AWS, query your resources, potentially make", "tokens": [51176, 639, 1669, 309, 534, 1858, 281, 4648, 365, 17650, 11, 14581, 428, 3593, 11, 7263, 652, 51388], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 6, "seek": 0, "start": 20.48, "end": 22.32, "text": " changes to your resources.", "tokens": [51388, 2962, 281, 428, 3593, 13, 51480], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 7, "seek": 0, "start": 22.32, "end": 26.04, "text": " And then we have the Knowledge One, which brings in documentation, things from the Builder", "tokens": [51480, 400, 550, 321, 362, 264, 32906, 1485, 11, 597, 5607, 294, 14333, 11, 721, 490, 264, 11875, 260, 51666], "temperature": 0.0, "avg_logprob": -0.26581206688514125, "compression_ratio": 1.667785234899329, "no_speech_prob": 0.026781274005770683}, {"id": 8, "seek": 2604, "start": 26.04, "end": 27.04, "text": " Center.", "tokens": [50364, 5169, 13, 50414], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 9, "seek": 2604, "start": 27.04, "end": 32.4, "text": " And so both of these together actually make you super productive when you're working with AWS.", "tokens": [50414, 400, 370, 1293, 295, 613, 1214, 767, 652, 291, 1687, 13304, 562, 291, 434, 1364, 365, 17650, 13, 50682], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 10, "seek": 2604, "start": 32.4, "end": 33.4, "text": " So let's dive in.", "tokens": [50682, 407, 718, 311, 9192, 294, 13, 50732], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 11, "seek": 2604, "start": 33.4, "end": 34.8, "text": " I'll give you a quick demo.", "tokens": [50732, 286, 603, 976, 291, 257, 1702, 10723, 13, 50802], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 12, "seek": 2604, "start": 34.8, "end": 40.84, "text": " So here in Kuro, what I'm going to do is be able to edit this MCP.json file.", "tokens": [50802, 407, 510, 294, 591, 7052, 11, 437, 286, 478, 516, 281, 360, 307, 312, 1075, 281, 8129, 341, 8797, 47, 13, 73, 3015, 3991, 13, 51104], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 13, "seek": 2604, "start": 40.84, "end": 45.0, "text": " We can do get to that by opening up the Kuro menu, going to MCP servers, hitting this", "tokens": [51104, 492, 393, 360, 483, 281, 300, 538, 5193, 493, 264, 591, 7052, 6510, 11, 516, 281, 8797, 47, 15909, 11, 8850, 341, 51312], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 14, "seek": 2604, "start": 45.0, "end": 46.0, "text": " edit button.", "tokens": [51312, 8129, 2960, 13, 51362], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 15, "seek": 2604, "start": 46.0, "end": 50.08, "text": " And we'll see that I've put in both of those MCP servers, I just mentioned.", "tokens": [51362, 400, 321, 603, 536, 300, 286, 600, 829, 294, 1293, 295, 729, 8797, 47, 15909, 11, 286, 445, 2835, 13, 51566], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 16, "seek": 2604, "start": 50.08, "end": 54.08, "text": " The first one is that AWS API, MCP server.", "tokens": [51566, 440, 700, 472, 307, 300, 17650, 9362, 11, 8797, 47, 7154, 13, 51766], "temperature": 0.0, "avg_logprob": -0.177594030604643, "compression_ratio": 1.6346863468634687, "no_speech_prob": 0.05384023115038872}, {"id": 17, "seek": 5408, "start": 54.08, "end": 57.199999999999996, "text": " And that uses a tool called UV, a very used UV.", "tokens": [50364, 400, 300, 4960, 257, 2290, 1219, 17887, 11, 257, 588, 1143, 17887, 13, 50520], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 18, "seek": 5408, "start": 57.199999999999996, "end": 58.199999999999996, "text": " No, I haven't.", "tokens": [50520, 883, 11, 286, 2378, 380, 13, 50570], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 19, "seek": 5408, "start": 58.199999999999996, "end": 64.48, "text": " It's a great build tool for Python, makes it really easy to pull down a Python library", "tokens": [50570, 467, 311, 257, 869, 1322, 2290, 337, 15329, 11, 1669, 309, 534, 1858, 281, 2235, 760, 257, 15329, 6405, 50884], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 20, "seek": 5408, "start": 64.48, "end": 65.48, "text": " and run it.", "tokens": [50884, 293, 1190, 309, 13, 50934], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 21, "seek": 5408, "start": 65.48, "end": 66.48, "text": " So that's what we're using.", "tokens": [50934, 407, 300, 311, 437, 321, 434, 1228, 13, 50984], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 22, "seek": 5408, "start": 66.48, "end": 69.08, "text": " We're pulling down that server and starting it up.", "tokens": [50984, 492, 434, 8407, 760, 300, 7154, 293, 2891, 309, 493, 13, 51114], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 23, "seek": 5408, "start": 69.08, "end": 72.44, "text": " I'm putting it to my AWS region, US East One.", "tokens": [51114, 286, 478, 3372, 309, 281, 452, 17650, 4458, 11, 2546, 6747, 1485, 13, 51282], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 24, "seek": 5408, "start": 72.44, "end": 77.06, "text": " I'd give it a working directory because the AWS CLI actually needs to know what", "tokens": [51282, 286, 1116, 976, 309, 257, 1364, 21120, 570, 264, 17650, 12855, 40, 767, 2203, 281, 458, 437, 51513], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 25, "seek": 5408, "start": 77.06, "end": 80.32, "text": " directory it's in if it's going to copy files, that sort of thing.", "tokens": [51513, 21120, 309, 311, 294, 498, 309, 311, 516, 281, 5055, 7098, 11, 300, 1333, 295, 551, 13, 51676], "temperature": 0.0, "avg_logprob": -0.22701629996299744, "compression_ratio": 1.5977859778597785, "no_speech_prob": 0.039572350680828094}, {"id": 26, "seek": 8032, "start": 80.32, "end": 85.52, "text": " And then I can also set this read-only read operations only to true if I want to just", "tokens": [50364, 400, 550, 286, 393, 611, 992, 341, 1401, 12, 25202, 1401, 7705, 787, 281, 2074, 498, 286, 528, 281, 445, 50624], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 27, "seek": 8032, "start": 85.52, "end": 89.91999999999999, "text": " be safe to make sure that it's not going to go accidentally and mutating stuff in my AWS", "tokens": [50624, 312, 3273, 281, 652, 988, 300, 309, 311, 406, 516, 281, 352, 15715, 293, 5839, 990, 1507, 294, 452, 17650, 50844], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 28, "seek": 8032, "start": 89.91999999999999, "end": 90.91999999999999, "text": " infrastructure.", "tokens": [50844, 6896, 13, 50894], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 29, "seek": 8032, "start": 90.91999999999999, "end": 95.91999999999999, "text": " And so with this one, it does, it is going to give essentially the AI access to your AWS", "tokens": [50894, 400, 370, 365, 341, 472, 11, 309, 775, 11, 309, 307, 516, 281, 976, 4476, 264, 7318, 2105, 281, 428, 17650, 51144], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 30, "seek": 8032, "start": 95.91999999999999, "end": 96.91999999999999, "text": " environment.", "tokens": [51144, 2823, 13, 51194], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 31, "seek": 8032, "start": 96.91999999999999, "end": 101.28, "text": " So you probably want to put some safeguards and not use this for your production system,", "tokens": [51194, 407, 291, 1391, 528, 281, 829, 512, 32358, 84, 2287, 293, 406, 764, 341, 337, 428, 4265, 1185, 11, 51412], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 32, "seek": 8032, "start": 101.28, "end": 104.39999999999999, "text": " maybe just for exploring testing and that sort of thing.", "tokens": [51412, 1310, 445, 337, 12736, 4997, 293, 300, 1333, 295, 551, 13, 51568], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 33, "seek": 8032, "start": 104.39999999999999, "end": 105.39999999999999, "text": " So that's the first one.", "tokens": [51568, 407, 300, 311, 264, 700, 472, 13, 51618], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 34, "seek": 8032, "start": 105.39999999999999, "end": 106.39999999999999, "text": " Let me show you how to use it.", "tokens": [51618, 961, 385, 855, 291, 577, 281, 764, 309, 13, 51668], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 35, "seek": 8032, "start": 106.39999999999999, "end": 109.52, "text": " I'm going to go into Kuro into the vibe mode.", "tokens": [51668, 286, 478, 516, 281, 352, 666, 591, 7052, 666, 264, 14606, 4391, 13, 51824], "temperature": 0.0, "avg_logprob": -0.20915039271524508, "compression_ratio": 1.7197452229299364, "no_speech_prob": 0.08359439671039581}, {"id": 36, "seek": 10952, "start": 109.52, "end": 113.11999999999999, "text": " So what I'm going to do is tell it to you, list my S3 buckets.", "tokens": [50364, 407, 437, 286, 478, 516, 281, 360, 307, 980, 309, 281, 291, 11, 1329, 452, 318, 18, 32191, 13, 50544], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 37, "seek": 10952, "start": 113.11999999999999, "end": 116.96, "text": " And it's going to think about that for a second because it's actually using a pretty sophisticated", "tokens": [50544, 400, 309, 311, 516, 281, 519, 466, 300, 337, 257, 1150, 570, 309, 311, 767, 1228, 257, 1238, 16950, 50736], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 38, "seek": 10952, "start": 116.96, "end": 123.39999999999999, "text": " model to turn that into an AWS CLI command to then make the call up to AWS.", "tokens": [50736, 2316, 281, 1261, 300, 666, 364, 17650, 12855, 40, 5622, 281, 550, 652, 264, 818, 493, 281, 17650, 13, 51058], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 39, "seek": 10952, "start": 123.39999999999999, "end": 126.72, "text": " So before it does anything, it's going to ask me, are you sure you want to do this?", "tokens": [51058, 407, 949, 309, 775, 1340, 11, 309, 311, 516, 281, 1029, 385, 11, 366, 291, 988, 291, 528, 281, 360, 341, 30, 51224], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 40, "seek": 10952, "start": 126.72, "end": 127.72, "text": " Here's what I'm going to do.", "tokens": [51224, 1692, 311, 437, 286, 478, 516, 281, 360, 13, 51274], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 41, "seek": 10952, "start": 127.72, "end": 128.72, "text": " Are you sure?", "tokens": [51274, 2014, 291, 988, 30, 51324], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 42, "seek": 10952, "start": 128.72, "end": 130.35999999999999, "text": " And I'm going to say, yep, I'm sure run it.", "tokens": [51324, 400, 286, 478, 516, 281, 584, 11, 18633, 11, 286, 478, 988, 1190, 309, 13, 51406], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 43, "seek": 10952, "start": 130.35999999999999, "end": 135.0, "text": " And then what will happen is we'll see the output from this call, kind of stream in there.", "tokens": [51406, 400, 550, 437, 486, 1051, 307, 321, 603, 536, 264, 5598, 490, 341, 818, 11, 733, 295, 4309, 294, 456, 13, 51638], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 44, "seek": 10952, "start": 135.0, "end": 138.64, "text": " But you'll see there, guys, it listed my S3 buckets, even gave me some information", "tokens": [51638, 583, 291, 603, 536, 456, 11, 1074, 11, 309, 10052, 452, 318, 18, 32191, 11, 754, 2729, 385, 512, 1589, 51820], "temperature": 0.0, "avg_logprob": -0.1739074502672468, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.010901251807808876}, {"id": 45, "seek": 13864, "start": 138.64, "end": 141.11999999999998, "text": " about when there created gives me a little summary.", "tokens": [50364, 466, 562, 456, 2942, 2709, 385, 257, 707, 12691, 13, 50488], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 46, "seek": 13864, "start": 141.11999999999998, "end": 142.11999999999998, "text": " So great.", "tokens": [50488, 407, 869, 13, 50538], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 47, "seek": 13864, "start": 142.11999999999998, "end": 146.92, "text": " Now I've got this like natural language interface to talk to my resources on AWS.", "tokens": [50538, 823, 286, 600, 658, 341, 411, 3303, 2856, 9226, 281, 751, 281, 452, 3593, 322, 17650, 13, 50778], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 48, "seek": 13864, "start": 146.92, "end": 149.92, "text": " Okay, the next one here is that knowledge server.", "tokens": [50778, 1033, 11, 264, 958, 472, 510, 307, 300, 3601, 7154, 13, 50928], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 49, "seek": 13864, "start": 149.92, "end": 156.0, "text": " So this one has access to a number of documents on AWS documentation, the new builder", "tokens": [50928, 407, 341, 472, 575, 2105, 281, 257, 1230, 295, 8512, 322, 17650, 14333, 11, 264, 777, 27377, 51232], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 50, "seek": 13864, "start": 156.0, "end": 157.0, "text": " center.", "tokens": [51232, 3056, 13, 51282], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 51, "seek": 13864, "start": 157.0, "end": 159.64, "text": " So index is all that and can search that.", "tokens": [51282, 407, 8186, 307, 439, 300, 293, 393, 3164, 300, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 52, "seek": 13864, "start": 159.64, "end": 164.04, "text": " And so for that, I did have to use this MCP proxy, also using UV.", "tokens": [51414, 400, 370, 337, 300, 11, 286, 630, 362, 281, 764, 341, 8797, 47, 29690, 11, 611, 1228, 17887, 13, 51634], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 53, "seek": 13864, "start": 164.04, "end": 168.32, "text": " And then I tell that the transport is the MCP streamable HTTP protocol.", "tokens": [51634, 400, 550, 286, 980, 300, 264, 5495, 307, 264, 8797, 47, 4309, 712, 33283, 10336, 13, 51848], "temperature": 0.0, "avg_logprob": -0.23995719909667967, "compression_ratio": 1.6215277777777777, "no_speech_prob": 0.05070434883236885}, {"id": 54, "seek": 16832, "start": 168.32, "end": 170.04, "text": " And then I just give it the URL.", "tokens": [50364, 400, 550, 286, 445, 976, 309, 264, 12905, 13, 50450], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 55, "seek": 16832, "start": 170.04, "end": 175.44, "text": " And now I can come in and ask it questions like, I'm going to say, how do I deploy", "tokens": [50450, 400, 586, 286, 393, 808, 294, 293, 1029, 309, 1651, 411, 11, 286, 478, 516, 281, 584, 11, 577, 360, 286, 7274, 50720], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 56, "seek": 16832, "start": 175.44, "end": 178.2, "text": " with bedrock agent core runtime?", "tokens": [50720, 365, 2901, 17799, 9461, 4965, 34474, 30, 50858], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 57, "seek": 16832, "start": 178.2, "end": 182.23999999999998, "text": " And that's something that the model doesn't know, but this knowledge server knows.", "tokens": [50858, 400, 300, 311, 746, 300, 264, 2316, 1177, 380, 458, 11, 457, 341, 3601, 7154, 3255, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 58, "seek": 16832, "start": 182.23999999999998, "end": 187.51999999999998, "text": " And so now it's going to say, like, hey, I'm going to search the documentation for information", "tokens": [51060, 400, 370, 586, 309, 311, 516, 281, 584, 11, 411, 11, 4177, 11, 286, 478, 516, 281, 3164, 264, 14333, 337, 1589, 51324], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 59, "seek": 16832, "start": 187.51999999999998, "end": 188.51999999999998, "text": " about that.", "tokens": [51324, 466, 300, 13, 51374], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 60, "seek": 16832, "start": 188.51999999999998, "end": 190.28, "text": " I'm going to say, yep, I do want you to do that.", "tokens": [51374, 286, 478, 516, 281, 584, 11, 18633, 11, 286, 360, 528, 291, 281, 360, 300, 13, 51462], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 61, "seek": 16832, "start": 190.28, "end": 192.56, "text": " So it's calling the MCP tool.", "tokens": [51462, 407, 309, 311, 5141, 264, 8797, 47, 2290, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 62, "seek": 16832, "start": 192.56, "end": 195.35999999999999, "text": " And it's going to do a number of different operations.", "tokens": [51576, 400, 309, 311, 516, 281, 360, 257, 1230, 295, 819, 7705, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1659637785305942, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.01494714617729187}, {"id": 63, "seek": 19536, "start": 195.36, "end": 199.76000000000002, "text": " I can, I think, just say, like, accept all or whatever, but I'm going to prove each one", "tokens": [50364, 286, 393, 11, 286, 519, 11, 445, 584, 11, 411, 11, 3241, 439, 420, 2035, 11, 457, 286, 478, 516, 281, 7081, 1184, 472, 50584], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 64, "seek": 19536, "start": 199.76000000000002, "end": 200.76000000000002, "text": " individually.", "tokens": [50584, 16652, 13, 50634], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 65, "seek": 19536, "start": 200.76000000000002, "end": 202.12, "text": " It's going to read documentation.", "tokens": [50634, 467, 311, 516, 281, 1401, 14333, 13, 50702], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 66, "seek": 19536, "start": 202.12, "end": 206.96, "text": " So it's going to go through all these iterative steps, learning from the documentation.", "tokens": [50702, 407, 309, 311, 516, 281, 352, 807, 439, 613, 17138, 1166, 4439, 11, 2539, 490, 264, 14333, 13, 50944], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 67, "seek": 19536, "start": 206.96, "end": 210.72000000000003, "text": " And then we'll give me a nice summary of something that is brand new, which is super", "tokens": [50944, 400, 550, 321, 603, 976, 385, 257, 1481, 12691, 295, 746, 300, 307, 3360, 777, 11, 597, 307, 1687, 51132], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 68, "seek": 19536, "start": 210.72000000000003, "end": 214.72000000000003, "text": " cold to be able to have access to that type of information within Kuro.", "tokens": [51132, 3554, 281, 312, 1075, 281, 362, 2105, 281, 300, 2010, 295, 1589, 1951, 591, 7052, 13, 51332], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 69, "seek": 19536, "start": 214.72000000000003, "end": 218.08, "text": " I think something with AWS before, it's always hard to find the correct documentation.", "tokens": [51332, 286, 519, 746, 365, 17650, 949, 11, 309, 311, 1009, 1152, 281, 915, 264, 3006, 14333, 13, 51500], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 70, "seek": 19536, "start": 218.08, "end": 219.56, "text": " So this makes it much easier.", "tokens": [51500, 407, 341, 1669, 309, 709, 3571, 13, 51574], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 71, "seek": 19536, "start": 219.56, "end": 220.56, "text": " Yeah, exactly.", "tokens": [51574, 865, 11, 2293, 13, 51624], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 72, "seek": 19536, "start": 220.56, "end": 224.56, "text": " Like, this gives you the natural language interface to the documentation, so you don't have", "tokens": [51624, 1743, 11, 341, 2709, 291, 264, 3303, 2856, 9226, 281, 264, 14333, 11, 370, 291, 500, 380, 362, 51824], "temperature": 0.0, "avg_logprob": -0.22164518182927911, "compression_ratio": 1.7660818713450293, "no_speech_prob": 0.010008026845753193}, {"id": 73, "seek": 22456, "start": 224.56, "end": 228.88, "text": " to go search through the whole documentation website and the many other sites that are", "tokens": [50364, 281, 352, 3164, 807, 264, 1379, 14333, 3144, 293, 264, 867, 661, 7533, 300, 366, 50580], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 74, "seek": 22456, "start": 228.88, "end": 231.96, "text": " all indexed with this MCP tool as well.", "tokens": [50580, 439, 8186, 292, 365, 341, 8797, 47, 2290, 382, 731, 13, 50734], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 75, "seek": 22456, "start": 231.96, "end": 234.08, "text": " It's not just the normal documentation site.", "tokens": [50734, 467, 311, 406, 445, 264, 2710, 14333, 3621, 13, 50840], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 76, "seek": 22456, "start": 234.08, "end": 239.24, "text": " So you've probably had that situation where you open up like a hundred different tabs", "tokens": [50840, 407, 291, 600, 1391, 632, 300, 2590, 689, 291, 1269, 493, 411, 257, 3262, 819, 20743, 51098], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 77, "seek": 22456, "start": 239.24, "end": 241.8, "text": " in your browser, and then you have to go read through all those.", "tokens": [51098, 294, 428, 11185, 11, 293, 550, 291, 362, 281, 352, 1401, 807, 439, 729, 13, 51226], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 78, "seek": 22456, "start": 241.8, "end": 245.76, "text": " And this is essentially doing that all for you, doing that work for you, of taking all that", "tokens": [51226, 400, 341, 307, 4476, 884, 300, 439, 337, 291, 11, 884, 300, 589, 337, 291, 11, 295, 1940, 439, 300, 51424], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 79, "seek": 22456, "start": 245.76, "end": 249.24, "text": " information, distilling it down into exactly what you want to know.", "tokens": [51424, 1589, 11, 1483, 7345, 309, 760, 666, 2293, 437, 291, 528, 281, 458, 13, 51598], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 80, "seek": 22456, "start": 249.24, "end": 250.24, "text": " Great.", "tokens": [51598, 3769, 13, 51648], "temperature": 0.0, "avg_logprob": -0.2095884323120117, "compression_ratio": 1.6979166666666667, "no_speech_prob": 0.009795738384127617}, {"id": 81, "seek": 25024, "start": 250.24, "end": 255.84, "text": " We've got our documentation there for how to use this brand new agent core service.", "tokens": [50364, 492, 600, 658, 527, 14333, 456, 337, 577, 281, 764, 341, 3360, 777, 9461, 4965, 2643, 13, 50644], "temperature": 0.0, "avg_logprob": -0.21904576834985764, "compression_ratio": 1.7322834645669292, "no_speech_prob": 0.12126260995864868}, {"id": 82, "seek": 25024, "start": 255.84, "end": 258.12, "text": " And those are our two MCP servers.", "tokens": [50644, 400, 729, 366, 527, 732, 8797, 47, 15909, 13, 50758], "temperature": 0.0, "avg_logprob": -0.21904576834985764, "compression_ratio": 1.7322834645669292, "no_speech_prob": 0.12126260995864868}, {"id": 83, "seek": 25024, "start": 258.12, "end": 262.64, "text": " So if you want to get started, the best way is to go to the GitHub page, let's get up.com", "tokens": [50758, 407, 498, 291, 528, 281, 483, 1409, 11, 264, 1151, 636, 307, 281, 352, 281, 264, 23331, 3028, 11, 718, 311, 483, 493, 13, 1112, 50984], "temperature": 0.0, "avg_logprob": -0.21904576834985764, "compression_ratio": 1.7322834645669292, "no_speech_prob": 0.12126260995864868}, {"id": 84, "seek": 25024, "start": 262.64, "end": 267.76, "text": " slash AWS Labs slash MCP, and you can find that link below.", "tokens": [50984, 17330, 17650, 40047, 17330, 8797, 47, 11, 293, 291, 393, 915, 300, 2113, 2507, 13, 51240], "temperature": 0.0, "avg_logprob": -0.21904576834985764, "compression_ratio": 1.7322834645669292, "no_speech_prob": 0.12126260995864868}, {"id": 85, "seek": 25024, "start": 267.76, "end": 271.88, "text": " And then go to the Getting Started with AWS, and you can find the information on those", "tokens": [51240, 400, 550, 352, 281, 264, 13674, 39715, 365, 17650, 11, 293, 291, 393, 915, 264, 1589, 322, 729, 51446], "temperature": 0.0, "avg_logprob": -0.21904576834985764, "compression_ratio": 1.7322834645669292, "no_speech_prob": 0.12126260995864868}, {"id": 86, "seek": 25024, "start": 271.88, "end": 277.40000000000003, "text": " two MCP servers and how to install them into Kuro or wherever you want to use those.", "tokens": [51446, 732, 8797, 47, 15909, 293, 577, 281, 3625, 552, 666, 591, 7052, 420, 8660, 291, 528, 281, 764, 729, 13, 51722], "temperature": 0.0, "avg_logprob": -0.21904576834985764, "compression_ratio": 1.7322834645669292, "no_speech_prob": 0.12126260995864868}, {"id": 87, "seek": 27740, "start": 277.4, "end": 282.23999999999995, "text": " And I find really interesting is you could take these two MCP servers and use them together.", "tokens": [50364, 400, 286, 915, 534, 1880, 307, 291, 727, 747, 613, 732, 8797, 47, 15909, 293, 764, 552, 1214, 13, 50606], "temperature": 0.0, "avg_logprob": -0.1827674767909906, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.1519673466682434}, {"id": 88, "seek": 27740, "start": 282.23999999999995, "end": 284.44, "text": " So one can help you with documentation.", "tokens": [50606, 407, 472, 393, 854, 291, 365, 14333, 13, 50716], "temperature": 0.0, "avg_logprob": -0.1827674767909906, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.1519673466682434}, {"id": 89, "seek": 27740, "start": 284.44, "end": 288.4, "text": " One can actually help you craft and build your application using the API.", "tokens": [50716, 1485, 393, 767, 854, 291, 8448, 293, 1322, 428, 3861, 1228, 264, 9362, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1827674767909906, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.1519673466682434}, {"id": 90, "seek": 27740, "start": 288.4, "end": 292.44, "text": " If you liked this video, make sure you click like and subscribe, and let us know what", "tokens": [50914, 759, 291, 4501, 341, 960, 11, 652, 988, 291, 2052, 411, 293, 3022, 11, 293, 718, 505, 458, 437, 51116], "temperature": 0.0, "avg_logprob": -0.1827674767909906, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.1519673466682434}, {"id": 91, "seek": 27740, "start": 292.44, "end": 293.79999999999995, "text": " you want us to build next.", "tokens": [51116, 291, 528, 505, 281, 1322, 958, 13, 51184], "temperature": 0.0, "avg_logprob": -0.1827674767909906, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.1519673466682434}], "language": "en"}